{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279c2ab-b689-4e0e-be18-2cfc283688d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d43774a-45a7-4e8a-b1df-824b6fb6a228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SRC_PATH = \"../data/celebrities_seasons.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a86be-82ec-43e6-83a0-213698122ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(SRC_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18354279-e15b-419f-97e3-9e3cbc9a4cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"label\"].str.extract(\"([a-z]+-[a-z]+)-[a-z]+\")\n",
    "df[\"macro_label\"] = df[\"label\"].str.extract(\"[a-z]+-([a-z]+)\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0bb998-627f-4c03-b7a7-e835b8a28557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"macro_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf86ce-f7f0-473b-b515-bf7991fbb4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbcc7d-88ae-43ca-9d5d-d0e27717dfc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"], shuffle=True)\n",
    "np_train = np.vstack(train_df[\"embedding\"].tolist())\n",
    "np_test = np.vstack(test_df[\"embedding\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae79d20-a156-43f8-9691-522ecb7da7fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, accuracy_score\n",
    "from collections import Counter\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "def max_accuracy_dummy_classifier(clf, X: np.ndarray, y: np.ndarray) -> float:\n",
    "    _ = clf, X\n",
    "    counts = np.array(list(Counter(y).values()))\n",
    "    p = counts / counts.sum()\n",
    "    return (p ** 2).sum()\n",
    "\n",
    "\n",
    "def evaluate_classifier(clf, train_df: pd.DataFrame, label: str = \"macro_label\") -> dict:\n",
    "    metrics = cross_validate(\n",
    "        clf, \n",
    "        np.vstack(train_df[\"embedding\"]), \n",
    "        train_df[label],\n",
    "        return_train_score=True,\n",
    "        scoring={\n",
    "            \"accuracy\": make_scorer(accuracy_score),\n",
    "            \"macro_precision\": make_scorer(precision_score, average=\"macro\"),\n",
    "            \"min_precision\": lambda _clf, X, y: precision_score(y, _clf.predict(X), average=None).min(),\n",
    "            \"H(Y|X) [bits]\": lambda _clf, X, y: entropy(_clf.predict_proba(X), base=2, axis=1).mean(),\n",
    "            \"max_accuracy_dummy_classifier\": max_accuracy_dummy_classifier\n",
    "        }\n",
    "    )\n",
    "    metrics_d = {k: x.mean() for k, x in metrics.items()}\n",
    "    metrics_d[\"classifier\"] = str(clf)\n",
    "    return metrics_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95ee55-b030-42fd-aae5-612c90c382b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis, KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "nca_knn = Pipeline([('nca', nca), ('knn', knn)])\n",
    "\n",
    "svc = SVC(random_state=42, probability=True)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16, 8), max_iter=1000, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    gnb,\n",
    "    rf,\n",
    "    nca_knn,\n",
    "    svc,\n",
    "    mlp\n",
    "]\n",
    "\n",
    "\n",
    "metrics = map(lambda clf: pd.Series(evaluate_classifier(clf, train_df)), tqdm(classifiers))\n",
    "metrics_df = pd.concat(metrics, axis=1).T\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3009ee8e-ed31-4259-a287-3e2a685dd8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "K = 4\n",
    "\n",
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=K)\n",
    "nca_knn = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_knn.fit(np_train, train_df[\"macro_label\"])\n",
    "\n",
    "print(\"Train report\")\n",
    "train_pred = nca_knn.predict(np_train)\n",
    "print(classification_report(train_df[\"macro_label\"], train_pred))\n",
    "ConfusionMatrixDisplay.from_predictions(train_df[\"macro_label\"], train_pred)\n",
    "\n",
    "print(\"Test report\")\n",
    "np_test_pred = nca_knn.predict(np_test)\n",
    "np_knn_dist, np_knn_idx = knn.kneighbors(nca.transform(np_test), K)\n",
    "print(classification_report(test_df[\"macro_label\"], np_test_pred))\n",
    "ConfusionMatrixDisplay.from_predictions(test_df[\"macro_label\"], np_test_pred)\n",
    "\n",
    "p = nca_knn.predict_proba(np_test)\n",
    "h = entropy(p, base=2, axis=1)\n",
    "conditional_h = h.mean()\n",
    "print(\"H(Y|X):\", conditional_h, \"bits\")\n",
    "\n",
    "pred_df = test_df[[\"src_path\", \"macro_label\"]].copy()\n",
    "pred_df[\"pred\"] = np_test_pred\n",
    "pred_df[\"knn_dist\"] = np_knn_dist.tolist()\n",
    "pred_df[\"knn_idx\"] = np_knn_idx.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5112a5c0-9034-40f2-bc77-7aa9c34830b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gt_label = \"winter\"\n",
    "pred_label = \"autumn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a86676-df1f-4f9b-8cf7-5c5f9ed3fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "misclassified_paths = pred_df.loc[(pred_df[\"macro_label\"] == gt_label) & (pred_df[\"pred\"] == pred_label), [\"src_path\"]]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(len(misclassified_paths), K + 1),  # creates 2x2 grid of Axes\n",
    "                 axes_pad=0.2,  # pad between Axes in inch.\n",
    "                 )\n",
    "grid = iter(grid)\n",
    "for i, (t, row) in enumerate(misclassified_paths.iterrows(), 1):\n",
    "    src_path = row[\"src_path\"]\n",
    "    knn_dist = pred_df.loc[t, \"knn_dist\"]\n",
    "    knn_idx = pred_df.loc[t, \"knn_idx\"]\n",
    "    knn_src_paths = train_df.iloc[knn_idx][\"src_path\"]\n",
    "    ax = next(grid)\n",
    "    #plt.subplot(len(misclassified_paths), len(knn_src_paths) + 1, i * len(knn_src_paths))\n",
    "    ax.imshow(np.array(Image.open(f\"../{src_path}\").resize((128, 128))))\n",
    "    for j, (nn_dist, nn_src_path) in enumerate(zip(knn_dist, knn_src_paths), 1): \n",
    "        #plt.subplot(len(misclassified_paths), len(knn_src_paths) + 1, i * len(knn_dist) + j)\n",
    "        ax = next(grid)\n",
    "        ax.imshow(np.array(Image.open(f\"../{nn_src_path}\").resize((128, 128))))\n",
    "        ax.set_title(f\"{nn_dist:.2f}\", fontdict={\"fontsize\": 7})\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a3241-8db7-4b4f-8d2c-696729e64b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
