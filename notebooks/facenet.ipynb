{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9279c2ab-b689-4e0e-be18-2cfc283688d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, accuracy_score\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9a25ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_path</th>\n",
       "      <th>embedding</th>\n",
       "      <th>name</th>\n",
       "      <th>season</th>\n",
       "      <th>macroseason</th>\n",
       "      <th>macrolabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/lfw-deepfunneled/Aaron_Eckhart/Aaron_Eckh...</td>\n",
       "      <td>[-0.008572585880756378, -0.09566288441419601, ...</td>\n",
       "      <td>Aaron Eckhart</td>\n",
       "      <td>true-spring-celebrities</td>\n",
       "      <td>spring</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>data/lfw-deepfunneled/Adriana_Lima/Adriana_Lim...</td>\n",
       "      <td>[0.034277111291885376, -0.037622272968292236, ...</td>\n",
       "      <td>Adriana Lima</td>\n",
       "      <td>soft-summer-celebrities</td>\n",
       "      <td>summer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>data/lfw-deepfunneled/Adrien_Brody/Adrien_Brod...</td>\n",
       "      <td>[-0.028514988720417023, -0.07194817066192627, ...</td>\n",
       "      <td>Adrien Brody</td>\n",
       "      <td>bright-winter-celebrities</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>data/lfw-deepfunneled/Adrien_Brody/Adrien_Brod...</td>\n",
       "      <td>[-0.04232393950223923, -0.03775602579116821, -...</td>\n",
       "      <td>Adrien Brody</td>\n",
       "      <td>bright-winter-celebrities</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>data/lfw-deepfunneled/Adrien_Brody/Adrien_Brod...</td>\n",
       "      <td>[-0.02667202800512314, -0.035010598599910736, ...</td>\n",
       "      <td>Adrien Brody</td>\n",
       "      <td>bright-winter-celebrities</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         original_path  \\\n",
       "2    data/lfw-deepfunneled/Aaron_Eckhart/Aaron_Eckh...   \n",
       "97   data/lfw-deepfunneled/Adriana_Lima/Adriana_Lim...   \n",
       "100  data/lfw-deepfunneled/Adrien_Brody/Adrien_Brod...   \n",
       "101  data/lfw-deepfunneled/Adrien_Brody/Adrien_Brod...   \n",
       "102  data/lfw-deepfunneled/Adrien_Brody/Adrien_Brod...   \n",
       "\n",
       "                                             embedding           name  \\\n",
       "2    [-0.008572585880756378, -0.09566288441419601, ...  Aaron Eckhart   \n",
       "97   [0.034277111291885376, -0.037622272968292236, ...   Adriana Lima   \n",
       "100  [-0.028514988720417023, -0.07194817066192627, ...   Adrien Brody   \n",
       "101  [-0.04232393950223923, -0.03775602579116821, -...   Adrien Brody   \n",
       "102  [-0.02667202800512314, -0.035010598599910736, ...   Adrien Brody   \n",
       "\n",
       "                        season macroseason  macrolabel  \n",
       "2      true-spring-celebrities      spring           2  \n",
       "97     soft-summer-celebrities      summer           1  \n",
       "100  bright-winter-celebrities      winter           0  \n",
       "101  bright-winter-celebrities      winter           0  \n",
       "102  bright-winter-celebrities      winter           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load labeled dataset\n",
    "\n",
    "if os.path.exists(\"../data/lfw_facenet_embeddings_label_spreading.parquet\"):\n",
    "    # try local path\n",
    "    df = pd.read_parquet(\"../data/lfw_facenet_embeddings_label_spreading.parquet\")\n",
    "else:\n",
    "    # download from Hugging Face\n",
    "    df = pd.read_parquet(\"hf://datasets/lajota13/lfw_facenet_embeddings/lfw_facenet_embeddings_label_spreading.parquet\")\n",
    "    df.to_parquet(\"../data/lfw_facenet_embeddings_label_spreading.parquet\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68cbcc7d-88ae-43ca-9d5d-d0e27717dfc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split dataset in training and test on the basis of the celebrities' names\n",
    "\n",
    "train_names, test_names = train_test_split(\n",
    "    df[\"name\"].drop_duplicates().to_frame(), \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "train_df = df.merge(train_names, on=\"name\", how=\"inner\")\n",
    "test_df = df.merge(test_names, on=\"name\", how=\"inner\")\n",
    "np_train = np.vstack(train_df[\"embedding\"].tolist())\n",
    "np_test = np.vstack(test_df[\"embedding\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae79d20-a156-43f8-9691-522ecb7da7fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def max_accuracy_dummy_classifier(clf, X: np.ndarray, y: np.ndarray) -> float:\n",
    "    _ = clf, X\n",
    "    counts = np.array(list(Counter(y).values()))\n",
    "    p = counts / counts.sum()\n",
    "    return (p ** 2).sum()\n",
    "\n",
    "\n",
    "def evaluate_classifier(clf, train_df: pd.DataFrame, label: str = \"macroseason\") -> dict:\n",
    "    metrics = cross_validate(\n",
    "        clf, \n",
    "        np.vstack(train_df[\"embedding\"]), \n",
    "        train_df[label],\n",
    "        return_train_score=True,\n",
    "        scoring={\n",
    "            \"accuracy\": make_scorer(accuracy_score),\n",
    "            \"macro_precision\": make_scorer(precision_score, average=\"macro\"),\n",
    "            \"min_precision\": lambda _clf, X, y: precision_score(y, _clf.predict(X), average=None).min(),\n",
    "            \"H(Y|X) [bits]\": lambda _clf, X, y: entropy(_clf.predict_proba(X), base=2, axis=1).mean(),\n",
    "            \"max_accuracy_dummy_classifier\": max_accuracy_dummy_classifier\n",
    "        }\n",
    "    )\n",
    "    metrics_d = {k: x.mean() for k, x in metrics.items()}\n",
    "    metrics_d[\"classifier\"] = str(clf)\n",
    "    return metrics_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b95ee55-b030-42fd-aae5-612c90c382b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6446fded596b425e929211763fed6381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_macro_precision</th>\n",
       "      <th>train_macro_precision</th>\n",
       "      <th>test_min_precision</th>\n",
       "      <th>train_min_precision</th>\n",
       "      <th>test_H(Y|X) [bits]</th>\n",
       "      <th>train_H(Y|X) [bits]</th>\n",
       "      <th>test_max_accuracy_dummy_classifier</th>\n",
       "      <th>train_max_accuracy_dummy_classifier</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069232</td>\n",
       "      <td>0.077839</td>\n",
       "      <td>0.408927</td>\n",
       "      <td>0.546728</td>\n",
       "      <td>0.4243</td>\n",
       "      <td>0.546054</td>\n",
       "      <td>0.330142</td>\n",
       "      <td>0.413625</td>\n",
       "      <td>0.174184</td>\n",
       "      <td>0.151418</td>\n",
       "      <td>0.269779</td>\n",
       "      <td>0.269778</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.553989</td>\n",
       "      <td>0.192264</td>\n",
       "      <td>0.512002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.517593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.425137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.848524</td>\n",
       "      <td>0.954931</td>\n",
       "      <td>0.269779</td>\n",
       "      <td>0.269778</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117.98671</td>\n",
       "      <td>18.349576</td>\n",
       "      <td>0.572406</td>\n",
       "      <td>0.917118</td>\n",
       "      <td>0.581007</td>\n",
       "      <td>0.909931</td>\n",
       "      <td>0.456266</td>\n",
       "      <td>0.878296</td>\n",
       "      <td>1.041937</td>\n",
       "      <td>0.635293</td>\n",
       "      <td>0.269779</td>\n",
       "      <td>0.269778</td>\n",
       "      <td>SVC(probability=True, random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.101092</td>\n",
       "      <td>0.061888</td>\n",
       "      <td>0.476895</td>\n",
       "      <td>0.743838</td>\n",
       "      <td>0.472948</td>\n",
       "      <td>0.722929</td>\n",
       "      <td>0.39327</td>\n",
       "      <td>0.649359</td>\n",
       "      <td>1.089404</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.269779</td>\n",
       "      <td>0.269778</td>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(16, 8), max_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time score_time test_accuracy train_accuracy test_macro_precision  \\\n",
       "0   0.069232   0.077839      0.408927       0.546728               0.4243   \n",
       "1  19.553989   0.192264      0.512002            1.0             0.517593   \n",
       "2  117.98671  18.349576      0.572406       0.917118             0.581007   \n",
       "3  35.101092   0.061888      0.476895       0.743838             0.472948   \n",
       "\n",
       "  train_macro_precision test_min_precision train_min_precision  \\\n",
       "0              0.546054           0.330142            0.413625   \n",
       "1                   1.0           0.425137                 1.0   \n",
       "2              0.909931           0.456266            0.878296   \n",
       "3              0.722929            0.39327            0.649359   \n",
       "\n",
       "  test_H(Y|X) [bits] train_H(Y|X) [bits] test_max_accuracy_dummy_classifier  \\\n",
       "0           0.174184            0.151418                           0.269779   \n",
       "1           1.848524            0.954931                           0.269779   \n",
       "2           1.041937            0.635293                           0.269779   \n",
       "3           1.089404            0.959213                           0.269779   \n",
       "\n",
       "  train_max_accuracy_dummy_classifier  \\\n",
       "0                            0.269778   \n",
       "1                            0.269778   \n",
       "2                            0.269778   \n",
       "3                            0.269778   \n",
       "\n",
       "                                          classifier  \n",
       "0                                       GaussianNB()  \n",
       "1            RandomForestClassifier(random_state=42)  \n",
       "2             SVC(probability=True, random_state=42)  \n",
       "3  MLPClassifier(hidden_layer_sizes=(16, 8), max_...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis, KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "nca_knn = Pipeline([('nca', nca), ('knn', knn)])\n",
    "\n",
    "svc = SVC(random_state=42, probability=True)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16, 8), max_iter=1000, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    gnb,\n",
    "    rf,\n",
    "    #nca_knn,\n",
    "    svc,\n",
    "    mlp\n",
    "]\n",
    "\n",
    "\n",
    "metrics = map(lambda clf: pd.Series(evaluate_classifier(clf, train_df)), tqdm(classifiers))\n",
    "metrics_df = pd.concat(metrics, axis=1).T\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
